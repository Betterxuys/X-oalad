# 项目可行性研究报告

## 目录

一、项目介绍

* 1.项目名称
* 2.项目概述
* 3.项目目标

二、技术可行性

三、经济可行性

四、计划日程

## 项目介绍

### 1.项目名称

本项目名称暂定为“眼动追踪技术新方法及其在人机交互中的应用”

### 2.项目概述

本项目旨在建立一个低成本的新方式，利用简单的头戴设备或者桌面设备（包括设备自带设备，如摄像头），对用户的视线信息做出分析，提取出有效信息作为机器输入，从而作为一种新的机器控制方法。具体地说，我们希望能从用户眼部信息中，实时的定位用户关注的屏幕区域、进行注视检测、提供辅助阅读等功能。
我们希望克服目前眼动追踪技术中设备成本高、便携性差的问题，制作出一个“即插即用、随身携带”级别的设备。另外，我们希望方法尽可能的简单，能够用一个精简的驱动乃至集成至操作系统中实现，而不是消耗巨大的计算资源。
我们不会将重点放在精确性和高帧率上，原因是目前眼动追踪技术已经足够精确，采样频率也足够高。而我们项目面向便携设备，难以在这两点上与大型设备或接触式设备相提并论。对于精确性和采样频率，我们将以实用性为标准，在能保证使用的情况下尽可能精简设备、节约计算资源。

### 3.项目目标

根据具体情况，我们为不同时间点拟定了不同的项目目标，基础目标是项目的最低要求，中长期目标是在基础目标的条件下的进一步优化和改进。项目目标也会根据项目实际完成情况进行调整。大致计划如下：

#### 3.1.基础目标

项目的基础目标是在不需要额外硬件设备的条件下，利用设备自带的前置摄像头，完成一个基础的视线分类器。实现对特定用户（或用户组）视线在屏幕上的焦点进行区域归类。这个阶段最基础的目标是二区域分类，即将屏幕划分为两个部分（左右或上下），对用户视线进行二分类判断。在二区域分类的基础上，可尝试实现四区域、九区域的分类功能。
这个阶段对采样率要求在1Hz左右，并保证运算实时性，可以进行前置的训练工作。在这个阶段，我们还会首先才用一些较强假设，如用户在使用过程中头部相对于屏幕的位置没有改变， 所以注视点的改变仅仅是由眼部状态改变导致的。

预计实现算法：

* 1.实时图像提取：在程序中实时地提取摄像头图像并进行处理的功能。预估可用OpenCV内置接口和设备摄像头实现。
* 2.面部分层识别：在图像中分层识别面部、眼部、瞳孔的位置。并能截取出格式较为统一的眼部图像并标记瞳孔位置，以便作为数据使用。可能通过OpenCV提供的层级分类器或其它开源分类器实现。 
* 3.简单分类器：将眼部图像按照注视位置分类的分类器。能够判断特定格式眼部图像所注视的屏幕位置，最简单的为二分类器。可能用各类机器学习算法实现。

#### 3.2.中期目标

中期目标是在基础目标之上完成的。在这个阶段，我们将尝试进行较为准确的注视点定位，定位精度预计应在半径1cm以内（以13英寸屏幕为基准）。计划中我们将改进基础目标中的分类算法，使之可以处理连续的位置信息，同时我们将尝试加入一些桌面外部设备，如利用多个外接摄像头，以取得更多的数据，通过数据之间的互相校验，来提高注视点定位的精度。
在这个阶段，我们还将尝试完成一些除了注视点定位之外的眼神控制功能，可能包括注视唤醒、阅读自动滑动等，进一步丰富预期中眼动人机交互系统的功能。另外，我们将尽可能增加通用性，减少（或消除）新用户使用时的训练时间。我们仍将假设用户的头部在使用过程中没有移动。

预计实现算法：

* 1.相对位置计算：利用摄像头实时画面，根据提取出的数据计算出聚焦点位置和摄像头位置的平面距离。可能用到使用到卷积神经网络（CNN）。
* 2.注视判断：根据实时画面判断用户是否注视摄像头。当用户注视摄像头时，软件能收到提示信号。可能用到和短期目标中相近（也可能不同）的分类算法。
* 3.位置估计：根据多个相对位置（及到固定位置点的距离）估计出对应聚焦点平面位置。可能用到平面三点定位算法及各种误差降低手段。

#### 3.3.长期目标

长期目标旨在完成一个功能完整的设备以及配套驱动，能够对计算机进行简单操作（可能的操作包括移动光标、点击、唤醒、显示边缘菜单等）。这要求注视点定位更加精确，以及更多操作功能的完成。为了达成这个目的，我们可能会加入头戴式设备来与桌面设备进行配合。

重要的一点是，在前两个目标中，我们都假设了用户头部与屏幕的相对位置保持恒定，这在日常使用中很难保证。在我们的长期规划中，将初步解决这个问题。而头戴式设备与这个问题有着密不可分的联系，头戴式设备的设计和配套软件的设计将是长期目标中的重要一环。

预计实现算法：

* 1.头部定位：根据设备摄像头对头部相对于屏幕位置进行定位的算法。如果可能还将给出头部的偏向角。
* 2.近距离视线角：利用头戴设备上的摄像头或其它传感器，在近距离对视线偏向角进行计算，给出较精确数据。
* 3.操作检测：将以上各个算法的数据进行处理，从大量的实时数据中快速提取出相应操作。

## 技术可行性

该章将对项目目标中的提到的预计实现算法的实现方法进行探讨，分析项目可行性。

### 1.算法可行性分析
#### 1.1 项目需求分析

本项目内容为通过眼球运动控制鼠标，因此需要较快的响应速度以及准确率为评价指标。在目前阶段，我们还要考虑训练数据较少，硬件条件问题，因此需要综合考虑算法运用。

#### 1.2 主要挑战
 
图像识别看似很直接。但实际上包含很多挑战，人类可是经过数亿年的进化才获得如此强大的大脑，对于各种物体有着精准的视觉理解力。总体而言，我们想『教』会计算机去认识一类图，会有下面这样一些困难：
•	视角不同，每个事物旋转或者侧视最后的构图都完全不同
•	尺寸大小不统一，相同内容的图片也可大可小
•	变形，很多东西处于特殊的情形下，会有特殊的摆放和形状
•	光影等干扰/幻象
•	背景干扰
•	同类内的差异(比如椅子有靠椅/吧椅/餐椅/躺椅…)

#### 1.3 算法调研

##### 1.3.1 特征提取部份

众所周知，计算机不认识图像,只认识数字。为了使计算机能够“理解”图像，从而具有真正意义上的“视觉”，本章我们将研究如何从图像中提取有用的数据或信息，得到图像的“非图像” 的表示或描述，如数值、向量和符号等。这一过程就是特征提取，而提取出来的这些“非图像”的表示或描述就是特征。有了这些数值或向量形式的特征我们就可以通过训练过程教会计算机如何懂得这些特征， 从而使计算机具有识别图像的本领。

其中，可以通过归纳“词袋”（bag of words）,人工提取特征；也可以利用卷积，滤波等方法提取特征。工具如python的scikit-learn等有工具包用于特征提取，可用于基本机器学习算法。

##### 1.3.2 特征编码部分

对于提取的特征，进行编码后才能送入分类器。常见的如灰度编码，黑白编码，独热码，以及决策树的标签等等。

##### 1.3.3 分类器部分

本次实验中，我们会主要利用机器学习方法进行分类，并尝试少量深度学习如卷积神经网络。


###### 1.3.3.1 决策树

主要内容

决策树是机器学习中一类常见算法，其核心思想是通过构建一个树状模型来对新样本进行预测。树的叶结点是决策结果，而所有非叶结点对应于一个个决策过程。

基本流程

一般的，一颗决策树包含一个根结点、若干内部结点和若干个叶结点；叶结点对应于决策结果，其它每个内部结点（包括根结点）则对应一个属性测试。决策树根据内部结点的属性测试结果将该结点所包含的样本集按照属性测试的结果被划分到不同的子结点中。这是一种简单且直观的“分而治之”（divide-and-conquer）策略。
决策树学习的目的是为了产生一颗泛化能力强的决策树。
 
![](https://github.com/OSH-2018/X-oalad/blob/master/Feasibility%20Study/pictures/decision%20tree.jpg)
 
上图是一棵结构简单的决策树，用于预测贷款用户是否具有偿还贷款的能力。
能力评估
	决策树的逻辑清晰，训练较简单，对于简单的分类问题可能性能较好。缺点在于，对于动态的跟踪，较难归纳特征；难以处理精确要求。算法性能可能随着精确度要求上升下降很多
  
###### 1.3.3.2 KNN（K-nearest-neighbor)

kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。

基本流程

1.	算距离：给定测试对象，计算它与训练集中每个对象的距离
2.	找邻居：圈定距离最近的K个训练对象，作为测试对象的近邻
3.	做分类：根据这K个近邻归属的主要类别，来对测试对象分类

![](https://github.com/OSH-2018/X-oalad/blob/master/Feasibility%20Study/pictures/knn-left.jpg)
![](https://github.com/OSH-2018/X-oalad/blob/master/Feasibility%20Study/pictures/knn-right.jpg)


能力评估

KNN算法可以对图像进行降维，且特征提取过程可以十分简单，仅需对像素进行划分，对于简单的分类也十分常用。缺点在于其对图像意义没有关注，分类标准较为单一。

###### 1.3.3.3 SVM(support vector machine)分类器

主要内容

SVM是一个由分类超平面定义的判别分类器。也就是说给定一组带标签的训练样本，算法将会输出一个最优超平面对新样本(测试样本)进行分类。

基本流程

计算函数间隔：在超平面w*x+b=0确定的情况下，|w*x+b|能够表示点x到距离超平面的远近，而通过观察w*x+b的符号与类标记y的符号是否一致可判断分类是否正确，所以，可以用(y*(w*x+b))的正负性来判定或表示分类的正确性。

最大化分类：对一个数据点进行分类，当超平面离数据点的“间隔”越大，分类的确信度（confidence）也越大。所以，为了使得分类的确信度尽量高，需要让所选择的超平面能够最大化这个“间隔”值。

求解对偶问题：通过拉格朗日对偶性（Lagrange Duality）变换到对偶变量 (dual variable) 的优化问题，即通过求解原问题等价的对偶问题（dual problem）得到原始问题的最优解，这就是线性可分条件下支持向量机的对偶算法，这样做的优点在于：一者对偶问题往往更容易求解；二者可以自然的引入核函数，进而推广到非线性分类问题。

处理非线性问题：

核函数：计算两个向量在隐式映射过后的空间中的内积的函数叫做核函数 (Kernel Function)。核函数能简化映射空间中的内积运算，恰好在 SVM 里需要计算的地方数据向量总是以内积的形式出现的。这样避开了直接在高维空间中进行计算，而能得到等价的结果。常用核函数有多项式核、高斯核和线性核。

使用松弛变量处理 outliers：由于数据有噪音。对于这种偏离正常位置很远的数据点，我们称之为 outlier 。为了处理这种情况，SVM 允许数据点在一定程度上偏离一下超平面，这时就引入了松弛变量。

能力评估

SVM 可以通过松弛变量和核技巧，把线性不可分问题转变成线性可分。它在很多诸如文本分类、图像分类、字符识别等有很多应用，与我们的研究比较契合。另外，通过OVR SVMs和pairwise的方法，我们可以利用其实现多分类的方案。在我们后期的研究中有比较强的应用潜力。


###### 1.3.3.4 卷积神经网络

主要内容

卷积神经网络（Convolutional Neural Network,CNN）是一种前馈神经网络，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。 它包括卷积层(convolutional layer)和池化层(pooling layer)。

基本流程

卷积神经网络充分利用了输入由图像组成的事实，并以更合理的方式约束了体系结构。特别是，与常规的神经网络不同，ConvNet的各层具有三维排列的神经元：宽度，高度，深度。 （请注意，这里的词深度是指激活体积的第三维，而不是指完整神经网络的深度，可以指网络中的图层总数。）例如，CIFAR- 10是激活的输入量，并且体积具有32×32×3（分别为宽度，高度，深度）的尺寸。正如我们将很快看到的，一层中的神经元只会连接到它之前层的一个小区域，而不是以完全连接的方式连接到所有神经元。此外，CIFAR-10的最终输出层的尺寸为1x1x10，因为在ConvNet体系结构的末尾，我们会将整个图像缩减为沿深度维度排列的单个分数向量。这是一个可视化：

![](https://github.com/OSH-2018/X-oalad/blob/master/Feasibility%20Study/pictures/cnn.jpg)

左：常规h的3层神a经网络。右：一个CongvNet在n三个维度a（宽度，高度，深度）上排列它的神经元，如其中一个图层中的可视化。 ConvNet的每一层都将3D输入转换为神经元激活的3D输出。在这个例子中，红色输入层保存图像，所以它的宽度和高度将是图像的尺寸，并且深度将是3（红色，绿色，蓝色通道）。
ConvNet由图层组成。每个图层都有一个简单的API：它将输入转换为具有可能有或没有参数的可微函数的输出。

用于构建ConvNets的层
正如我们上面所描述的，一个简单的ConvNet是一系列图层，ConvNet的每一层通过可微函数将一个激活体积转换为另一个激活体积。我们使用三种主要类型的层来构建ConvNet体系结构：卷积层，池化层和完全连接层（正如在常规神经网络中所见）。
示例架构：简单ConvNet可以具有体系结构[INPUT - CONV - RELU - POOL - FC]。
用一些具体的数字来说明：
INPUT [32x32x3]将保存图像的原始像素值，在这种情况下，图像的宽度为32，高度为32，并具有三个颜色通道R，G，B。
CONV层将计算连接到输入中局部区域的神经元的输出，每个计算它们的权重与它们在输入体积中连接的一个小区域之间的点积。如果我们决定使用12个滤镜，这可能导致[32x32x12]的volume。
RELU层将应用针对每个元素的激活函数，例如将MAX（0，x）的
阈值设为零。这会使volume大小不变（[32x32x12]）。
POOL层将沿着空间维度（宽度，高度）执行下采样操作，从而产生诸如[16x16x12]的volume。
FC（即完全连接）层将计算每个类别的分数，从而得到大小为[1×1×10]的数量，其中每个数字对应于每个类别的分数，例如10个类别的CIFAR-10。和普通的神经网络一样，顾名思义，这个层中的每个神经元都将连接到前一volume中的所有数字。
通过这种方式，ConvNets将原始图像逐层从原始像素值转换为最终的类别分数。请注意，某些图层包含参数，其他图层则不包含。具体而言，CONV / FC层执行转换，这些转换不仅是输入图像中的激活，而且也是参数（神经元的权重和偏差）的函数。另一方面，RELU / POOL层将实现一个固定的功能。 CONV / FC图层中的参数将使用梯度下降进行训练，以便ConvNet计算的类别分数与每个图像的训练集中的标签一致。

### 2. Opencv
#### 2.1 简介
OpenCV的全称是Open Source Computer Vision Library，是一个跨平台的计算机视觉库。OpenCV是由英特尔公司发起并参与开发，以BSD许可证授权发行，可以在商业和研究领域中免费使用。OpenCV可用于开发实时的图像处理、计算机视觉以及模式识别程序。该程序库也可以使用英特尔公司的IPP进行加速处理。
#### 2.2 配置环境
以vs2017和opencv3.2.0为例
    a)安装：将opencv安装C盘中
    b)配置环境变量：计算机->属性->高级系统设置->环境变量 添加C:\ opencv\build\x64\vc14\bin
![](pictures/env1.png)
    c)新建项目c++控制台项目，将debug||X86设置成X64。
    d)右键项目属性，VC++目录->包含目录，添加 
    C:\opencv\build\include 
    C:\opencv\build\include\opencv 
    C:\opencv\build\include\opencv2 
    VC++目录->库目录，添加 
    C:\opencv\build\x64\vc14\lib 
    链接器->输入，添加 
    opencv_world320d.lib（release下添加opencv_world320.lib）
 ![](pictures/env2.png)

附测试用代码：
include <opencv2/opencv.hpp>
#include <iostream>
using namespace std;
using namespace cv;
int main()
{
    Mat image = imread("D:\\test.jpg");  //存放自己图像的路径 
    imshow("显示图像", image);
    waitKey(0);
    return 0;
}

#### 2.3 定位瞳孔的简单实现
    a)定位瞳孔可以直接使用opencv中的自带的分类器（haarcascade_eye_tree_eyeglasses.xml）来实现，做了实验后发现在正面人脸的情况下定位还是很准确的。注意haarcascade_eye_tree_eyeglasses.xml文件在opencv安装目录下的data文件夹中。
    b)用opencv中检测人脸、眼睛、嘴巴等都是用的CascadeClassifier分类器，具体使用时可以使用C的函数，也可以使用opencv中使用C++封装好的类。下面是它们检测目标时的函数形式:
C: CvSeq* cvHaarDetectObjects(const CvArr* image, CvHaarClassifierCascade* cascade,CvMemStorage* storage,double scale_factor=1.1, int min_neighbors=3, int flags=0, CvSize min_size=cvSize(0,0), CvSize max_size=cvSize(0,0) )

C++: void CascadeClassifier::detectMultiScale(const Mat& image, vector<Rect>& objects, double scaleFactor=1.1, int minNeighbors=3, int flags=0, Size minSize=Size(), Size maxSize=Size()

    这两者最大的区别在于，用C封装的函数要自己手动分配内存，而用C++的形式则不用自己去分配内存。显然C++形式的更加简洁。


能力评估

相比传统神经网络，卷积神经网络减少网络各层之间的连接，同时又降低了过拟合的风险，简化了模型复杂度，减少了模型的参数。其并行处理图像特征的方式也更符合动物行为。同时，其对特征的提取全面深入，因此在应用中取得了较好的成果。然而，其对象主要是大型图像处理，依然需要大量数据防止过拟合，所需训练时间也较长。针对此问题，我们或许可以通过采用视频截图的方式来训练。
## 经济可行性
本项目各阶段所要达到的任务目标不同，鉴于本实验的各阶段所需要的设备不同，且实验完成时间存在限制，故可分阶段对所需设备进行采购。
### 基础目标
基础目标所要实现的是对视线注视方向实现简单的二分类、四分类、九分类，在本阶段中我们可假设使用者在使用过程中头部不发生移动，故本阶段对设备的要求不高且，不需要头戴设备对头部进行定位。故仅需要使用电脑自带的摄像头即可，故本阶段所需花费资金为0。
### 中期目标
中期目标所要实现的是实现更加准确地进行注视点的定位并在此基础上处理注视点连续的位置信息，故在该阶段需要更为准确的实时数据，电脑自带的摄像头的精度可能无法满足要求。考虑通过增加摄像头的个数，获取不同角度的眼睛信息，对所获得的实时数据进行综合处理，提取更加精确的眼睛信息。由于在本阶段对摄像头清晰度要求不高，更多的是要采集不同的角度观察的眼睛信息。故暂定除电脑自带摄像头外，额外增加四个外置摄像头，每个摄像头约需40元。故在本阶段所需花费资金约为160元。
### 长期目标
长期目标所要实现的是用户在使用设备时头部可以移动，为实现该目标除了需要对眼睛位置进行实时的定位外，还要对头部的位置和角度等实现实时的定位，在该阶段除了需要签署设备外，需要一个与头部保持位置相对固定的摄像头，以及可将头部位置传递给电脑的传感器。由于头部的运动范围比较局限，故对传感器精度的要求较高，满足这样要求的传感器市场价格约为600元。

## 计划日程
时间 | 任务 
------------ | ------------
2018.4.30-2018.5.12 | 实现基础目标
2018.5.13 | 对第一阶段工作进行总结并对第二阶段工作进行安排
2018.5.14-2018.6.2 | 尝试实现中期目标
2018.6.3 | 对第二阶段工作进行总结并对后续计划进行修改
2018.6.4-6.17 | 对前两阶段工作进行修改并尝试进行第三阶段工作
2018.6.18-2018.7.1 | 进行最终的修改完善并进行成果展示





