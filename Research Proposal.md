# 眼动追踪技术调研报

## 目录

一、项目背景

* 1. 项目概述 (TODO:邓龙)
* 2. 知识基础（TODO：吴紫薇、于颖奇）
* 3. 发展历史（TODO：吴紫薇、于颖奇）
* 4. 技术背景与发展趋势（于颖奇）

二、立项依据

* 1. 技术基础
	* 1) OpenCV （邓龙）
	* 2) 机器学习 （TODO：戴路）
	* 3) 硬件驱动技术（TODO：徐煜森）
* 2. 项目目标（TODO:邓龙）
* 3. 研究思路（TODO：邓龙）
* 4. 项目优势介绍及重要性分析（TODO：徐煜森，从略）


三、前瞻性及重要性分析

* 1. 概述（邓龙）
* 2. 眼球追踪技术的重要性（TODO：徐煜森，详）
* 3. 应用前景（TODO：ALL）

四、相关工作和前沿进展

* 1. 学术界（重点，TODO：于颖奇、吴紫薇、戴路）
* 2. 工业界（重点，TODO：邓龙，徐煜森）


## 项目背景

### 1.项目概述

本项目名称暂定为“人机交互中的眼动追踪新方法”，旨在建立一个低成本的新方式，利用简单的头戴设备或者桌面设备（包括设备自带设备，如摄像头），对用户的视线信息做出分析，提取出有效信息作为机器输入，从而作为一种新的机器控制方法。具体地说，我们希望能从用户眼部信息中，实时的定位用户关注的屏幕区域、进行注视检测、提供辅助阅读等功能。
我们希望克服目前眼动追踪技术中设备成本高、便携性差的问题，制作出一个“即插即用、随身携带”级别的设备。另外，我们希望方法尽可能的简单，能够用一个精简的驱动乃至集成至操作系统中实现，而不是消耗巨大的计算资源。
我们不会将重点放在精确性和高帧率上，原因是目前眼动追踪技术已经足够精确，采样频率也足够高。而我们项目面向便携设备，难以在这两点上与大型设备或接触式设备相提并论。对于精确性和采样频率，我们将以实用性为标准，在能保证使用的情况下尽可能精简设备、节约计算资源。
关于更详细的项目情况，请参见立项依据部分。

### 2.知识基础

眼球跟踪(Eye tracking)是测量注视点（人眼看的地方）或眼睛相对于头部的运动的过程。眼动仪是用来测量眼睛位置和眼球移动的装置，在众多领域中的人机交互和产品设计中具有十分重要的应用。当前测量眼球移动的方法很多，其中应用最广泛的方法是通过分析视频来建立人眼位置与视线位置之间的关系。眼动仪是分析眼球运动的装置。当眼睛扫描环境或注视场景中的特定物体时，注视跟踪器会同时定位图像中的眼睛位置，并跟踪其随时间的移动以确定注视方向。眼睛检测和跟踪研究侧重于两个领域：图像中的眼睛定位(eye localization)和注视跟踪(gaze estimation)。眼睛检测有三个方面。一方面是检测眼睛的存在，另一方面是准确地解释图像中的眼睛位置，最后一方面则是在视频图像中检测眼睛在帧与帧之间的变化,通常通过测量瞳孔或虹膜中心位置测量眼睛的位置。在图像中跟踪眼睛位置用于估计和跟踪人物观看位置或者确定视线位置，这个过程被称为注视跟踪。

TODO：于颖奇(300)

### 3. 发展历史

（未完善，根据维基百科再补充，这个是看的论文里的）

Rayner在1998年将眼动追踪技术的发展分为4个阶段：

1879-1920 基本眼动事实的发现,包括：扫视抑制saccadic suppression

1930-1958 实验环境下心理学与行为分析

1970-1998 眼动记录系统的发展

1998-     眼动追踪技术的各种应用。当前主要应用领域有：神经科学


### 4. 技术背景及发展趋势

#### 4.1.测量眼球移动的方法

当前测量眼球移动的方法种类繁多。然而当前这些方法中没有十分满足当前需求的一种。进行眼球移动追踪首先我们需要明确的一点是，我们所关注的是视线所在位置，而不是眼球在空间中的绝对位置，或者与眼球相关的人脸表情。鉴于两只眼睛的指向方向一般相同，我们考虑只对其中的一只眼睛进行追踪。主要测量方法有以下几种：
1. 电子记录方法：在眼睛周围的皮肤上设置两个电极，通过测量眼角膜和视网膜随视线移动变化而发生的潜在变化，分析数据，建立电流大小与视线位置的相对关系。然而改种方法相较于测量人的视线位置，更适合于测量人脸表情所产生的变化。
2. 覆盖透镜测量：该种方法需要接住一个具有一定吸力的吸盘将一个透镜精确地覆盖在人的眼角膜上，然而这种方法只能适合于在实验室中进行测量，无很高的实际使用价值
3. 光学分析方法测量： 该种方法根据眼球的远距离成像的光学特点进行辅助测量（包括虹膜和巩膜的相对位置，瞳孔的大小，角膜对光的折射效应等），这种方法虽然会产生一定的误差，但相较于其他方法更具有实际应用的价值。

以上这些方法各有优劣，但他们却具有同样的一个缺点，即在眼球追踪时，头的相对位置不能发生任何移动，，只有这样才能保证所有的测量数据全都是由于眼球的移动产生的。然而如果能同时跟踪两个眼睛的多个不同特征，或许就能解决使用眼动仪头部僵直的问题，改种方法是当前最具实际应用价值的方式，通过使用这种方法我们不需要使测量仪器直接与人相接触，且人的头部可以任意移动。

#### 4.2.眼动数据可视化方法

已有研究提出了眼动数据可视化方法的基础框架，主要包括3个部分：可视化输入空间、可视化映射和可视化输出空间。[2]

根据可视化输出形式的不同，下表列出了当前已有的4类不同可视化方法的具体应用情景及优缺点。

![可视化方法比较](https://github.com/OSH-2018/X-oalad/blob/master/pictures/4_ways_of_visualization.png)

## 立项依据

### 1.技术基础

近年来，对于计算机视觉和人机交互相关领域的基础技术已经有了很大的发展，为新方法的出现提供了基础，可能用于眼球追踪的相关技术有OpenCV库，机器学习以及硬件驱动技术。

#### 1.1.OpenCV

近年来，随着机器学习的发展，许多库工具被制作出来用于处理人脸识别相关问题。OpenCV其中最知名也是较为成熟的一个。OpenCV是开源计算机视觉库（Open Source Computer Vision Library）的简称。是一个免费提供给学术和商业用途的计算机视觉库。OpenCV目标是为计算机视觉库提供一个通用的基础设施，并在商用产品中加速机器感知的使用。
OpenCV提供了许多优化算法，包括一些经典算法和机器学习算法。其提供的功能包括检测和识别人脸，识别物体，对视频中人的行为进行分类，跟踪摄像机运动，运动目标的跟踪，提取物体的三维模型等，也包括基本的图片和视频处理功能，以及一些机器学习库。
OpenCV提供C++、java、python、MATLAB等多种语言的接口，并且能够支持包括Windows、MacOS和Linux等多种平台。OpenCV已经广泛用于商业公司、研究团体和政府机构的工作中。
作为一个成熟的平台OpenCV使得我们能够无需自己动手造轮子，从而把精力集中在如何制造汽车上，其动态视频处理、人脸识别等功能和我们的需求高度近似，为我们的项目提供最基础的建设平台。

#### 1.2.机器学习

图像分类中的机器学习综述
图像分类是根据图像的语义信息将不同类别图像区分开来，是计算机视觉中重要的基本问题，也是图像检测、图像分割、物体跟踪、行为分析等其他高层视觉任务的基础。图像分类在很多领域有广泛应用，包括安防领域的人脸识别和智能视频分析等，交通领域的交通场景识别，互联网领域基于内容的图像检索和相册自动归类，医学领域的图像识别等。
一般来说，图像分类通过手工特征或特征学习方法对整个图像进行全部描述，然后使用分类器判别物体类别，因此如何提取图像的特征至关重要。在深度学习算法之前使用较多的是基于词袋(Bag of Words)模型的物体分类方法。词袋方法从自然语言处理中引入，即一句话可以用一个装了词的袋子表示其特征，袋子中的词为句子中的单词、短语或字。对于图像而言，词袋方法需要构建字典。最简单的词袋模型框架可以设计为底层特征抽取、特征编码、分类器设计三个过程

传统的有监督机器学习方法有决策树，回归分析（多分类回归）等方式。优点在于，特征数量少，所需数据少，训练时间短，原理透明可见。缺点在于，特征需要人工提取，有主观性；人工标记数据过程繁琐；难以囊括大量数据；特征丢失，难以全面。

而基于深度学习的图像分类方法，可以通过有监督或无监督的方式学习层次化的特征描述，从而取代了手工设计或选择图像特征的工作。
深度学习中，经常被用于图像分类的有卷积神经网络，迁移学习等。
深度学习模型中的卷积神经网络(Convolution Neural Network, CNN)近年来在图像领域取得了惊人的成绩，CNN直接利用图像像素信息作为输入，最大程度上保留了输入图像的所有信息，通过卷积操作进行特征的提取和高层抽象，模型输出直接是图像识别的结果。这种基于"输入-输出"直接端到端的学习方法取得了非常好的效果，得到了广泛的应用。然而，卷积神经网络需要大量的数据训练，防止过拟合现象。

迁移学习则可能提出了一种解决方法来弥补这一不足。迁移学习(Transfer learning) 顾名思义就是就是把已学训练好的模型参数迁移到新的模型来帮助新模型训练。考虑到大部分数据或任务是存在相关性的，所以通过迁移学习我们可以将已经学到的模型参数（也可理解为模型学到的知识）通过某种方式来分享给新模型从而加快并优化模型的学习效率不用像大多数网络那样从零学习（starting from scratch，tabula rasa）。在可行性报告中我们会进一步调研这些算法。


#### 1.3.硬件驱动技术

驱动程序是一个软件组件，它可让操作系统和设备彼此通信。例如，假设应用程序需要从设备中读取某些数据，应用程序会调用由操作系统实现的函数，操作系统会调用由驱动程序实现的函数。驱动程序（由设计和制造该设备的同一公司编写）了解如何与设备硬件通信以获取数据。当驱动程序从设备获取数据后，它会将数据返回到操作系统，操作系统将数据返回至应用程序。
微软为Windows驱动程序开发者提供一系列工具：Windows Driver Kit（WDK）10、Microsoft Visual Studio 2017、Windows调试工具。这些工具集成在一起为开发者提供开发、构建、打包、部署、测试和调试Windows驱动程序所需的工具。WDK包含用于多种技术和驱动程序模型的模板，包括Windows驱动程序框架（WDF）、通用串行总线（USB）等。
对于我们来说，微软专为非传统人机交互设备（human interface devices）驱动程序开发提供专用的函数，通过USB创建接口，允许为非传统HID设备创建通用驱动程序。我们将不用与直接系统底层接触，这将为开发带来很大方便。


### 2.项目目标

根据具体情况，我们为不同时间点拟定了不同的项目目标，基础目标是项目的最低要求，中长期目标是在基础目标的条件下的进一步优化和改进。项目目标也会根据项目实际完成情况进行调整。大致计划如下：

#### 2.1.基础目标

项目的基础目标是在不需要额外硬件设备的条件下，利用设备自带的前置摄像头，完成一个基础的视线分类器。实现对特定用户（或用户组）视线在屏幕上的焦点进行区域归类。这个阶段最基础的目标是二区域分类，即将屏幕划分为两个部分（左右或上下），对用户视线进行二分类判断。在二区域分类的基础上，可尝试实现四区域、九区域的分类功能。
-这个阶段对采样率要求在1Hz左右，并保证运算实时性，可以进行前置的训练工作。在这个阶段，我们还会首先才用一些较强假设，如用户在使用过程中头部相对于屏幕的位置没有改变， 所以注视点的改变仅仅是由眼部状态改变导致的。

#### 2.2.中期目标

中期目标是在基础目标之上完成的。在这个阶段，我们将尝试进行较为准确的注视点定位，定位精度预计应在半径1cm以内（以13英寸屏幕为基准）。计划中我们将改进基础目标中的分类算法，使之可以处理连续的位置信息，同时我们将尝试加入一些桌面外部设备，如利用多个外接摄像头，以取得更多的数据，通过数据之间的互相校验，来提高注视点定位的精度。
在这个阶段，我们还将尝试完成一些除了注视点定位之外的眼神控制功能，可能包括注视唤醒、阅读自动滑动等，进一步丰富预期中眼动人机交互系统的功能。另外，我们将尽可能增加通用性，减少（或消除）新用户使用时的训练时间。我们仍将假设用户的头部在使用过程中没有移动。

#### 2.3.长期目标

长期目标旨在完成一个功能完整的设备以及配套驱动，能够对计算机进行简单操作（可能的操作包括移动光标、点击、唤醒、显示边缘菜单等）。这要求注视点定位更加精确，以及更多操作功能的完成。为了达成这个目的，我们可能会加入头戴式设备来与桌面设备进行配合。

重要的一点是，在前两个目标中，我们都假设了用户头部与屏幕的相对位置保持恒定，这在日常使用中很难保证。在我们的长期规划中，将初步解决这个问题。而头戴式设备与这个问题有着密不可分的联系，头戴式设备的设计和配套软件的设计将是长期目标中的重要一环。

### 3.项目优势

当前虽然已经有了很多商业眼动跟踪设备出现在市场上，并且Google，Microsoft，Facebook等公司也纷纷收购相关公司，投入资本进行研发，但市场上主流的眼动仪成本仍然很高，所使用的技术仍是多年前的技术或其改进，没有一个真正低成本的新方法出现。本项目就旨在利用较低成本的设备实现可以实用的眼动追踪技术，从而形成新的人机交互方式。目前商用眼动仪大多用于医疗、教育、科研等方面，而没有融入日常生活，成本是至关重要的因素。本项目将从实际需求出发，在一定程度上降低对精确度和采样频率地追求，以达到改进成本和减少所需计算资源的目的。另外，本项目计划与近来热门的机器学习，特别是深度学习相结合，希望开创一个全新的方法，从全新的角度实现眼动追踪技术。
## 前瞻性及重要性分析


尽管当前眼镜检测模型多种多样，方法千差万别。但性能上均存在着不足，不能很好的满足需求，构建一个合适的眼睛检测模型，仍是当前面临且亟待解决的重要问题之一。### 1. 概述

视觉作为人感知外界的最重要感觉，在人机交互中不可或缺。在传统的人机交互设备中，视觉仅仅作为机器信息的一种输出方式，其在信息输入方面的作用一方面不被重视，一方面也由于技术原因难以利用。随着硬件技术（如GPU）和软件技术（如机器学习）的快速进步，以及包括VR、物联网等新的计算设备和概念的提出，眼球追踪作为一种新的人机交互方式，可以预见其的潜力将被逐渐发觉，成为未来人机交互模式中不可缺少的一部分。

### 2. 眼球追踪技术的重要性

TODO：徐煜森(1000)

### 3. 应用前景

TODO：ALL(2000~3000)

作为人脸最显着的特征之一，眼睛及其动作在表达一个人的欲望，需求，认知过程，情绪状态和人际关系方面起着重要作用。视觉运动对个人对视觉世界的感知和关注的重要性被隐含地承认，因为它是我们收集必要的信息以通过谈判来确定视觉世界的属性的方法。因此，健全的非侵入式眼睛检测和跟踪对于开发人机交互，细致的用户界面和理解人类情感状态至关重要。

眼睛独特的几何，光学和运动特征也为人脸检测，人脸识别和理解面部表情提供了重要的视觉线索。此外，眼睛之间的距离通常用于脸部正常化，用于其他脸部标志的定位以及滤除结构噪音。凝视估计和追踪对于许多应用是重要的，包括人类关注分(human attention analysis)，人类认知状态分析(human cognitive state analysis)，基于注视的交互式用户界面(gaze-based interactive user interfaces)，凝视偶然图形显示(gaze contingent graphical displays)。


## 相关工作及前沿进展

### 学术界

TODO：于颖奇、吴紫薇、戴路(3000~5000)

尽管近30年来积极的研究和显着的进展，但由于眼睛的个性，遮挡，尺度变化，位置和光线条件的影响，眼睛检测和跟踪仍然具有挑战性。关于眼睛位置和眼球运动细节的数据具有许多应用，并且在面部检测，生物识别和特定的人机交互任务中是必不可少的。
#### 眼睛检测模型
不管人眼位置是可动还是不可动的，人眼检测大致分为以下三类：基于眼睛形状的(shape-based)、基于人脸外观的(appearance-based)以及混合型的(hybrid methods )。基于形状的方法可以细分为固定形状和可变形形状。该方法由眼睛和脸部区域的局部点特征或轮廓构建。相关特征可以是边缘，眼角或根据特定滤波器选择的点。角膜缘和瞳孔是常用的检测点。虽然基于形状的方法使用眼睛形状和周围结构的先验模型，但基于外观的方法依赖于直接建立在眼睛区域外观上的模型。基于外观的方法（整体方法）在概念上涉及模板匹配，方法是构建图像块模型，并使用相似性度量，通过模型匹配执行眼睛检测。基于外观的方法可以进一步分为基于光强和子空间的方法。基于光强的方法直接使用光强或滤波强度图像作为模型，而子空间方法假定眼图像的重要信息是在较低维度的子空间中定义的。混合方法结合了特征，形状和外观方法来发挥各自的优点。

除此之外还有一些其他的方法，如利用对称性，参考瞬时的信息(如眨眼或表情)和通过不可见光(如：红外线)采集信息的的方法。其中采用红外光的方法普遍存在于眼镜检测的实验与应用中。尽管当前眼镜检测模型多种多样，方法千差万别。但性能上均存在着不足，不能很好的满足需求，构建一个合适的眼睛检测模型，仍是当前面临且亟待解决的重要问题之一。
#### 基于视频的眼睛检测和跟踪领域的最新进展和状态

#### 眼睛检测和跟踪的最新眼部模型和技术。

#### 凝视估计的方法，并根据它们的几何特性和报告的精度进行比较。

#### 低成本、大规模的众包眼动追踪技术

2015年普林斯顿大学的研究团队研究出基于网络摄像头的眼动追踪系统[3]，该方案充分利用了亚马逊土耳其机器人(MTurk)的数据集，完成了大规模的众包数据集的测试，行之有效。

#### 挑战

* 1. 在眼睛检测中，识别眼睛的模型十分重要，该模型需要充分考虑人的外观变化和动态变化对眼球识别的影响，同时要保证足够高的效率使得在人机交互过程中不会给使用者带来不适感。然而即使对于相同的主体，相对小的视角变化也会导致采集到的眼睛外观的显著变化。尽管已投入大量精力进行研究，眼睛检测和跟踪仍然是一个非常具有挑战性的任务，由于几个特有的问题，包括眼睛的部分遮挡，眼睛的开放程度，人眼的大小、光反射率不同及头部姿势的影响等。这使得其在计算机应用视觉领域，如人的跟踪，人脸检测和各种医疗应用，会遇到遮挡和形状变化灯复杂情况，很难达到预期的需求。


### 工业界

TODO：邓龙、徐煜森(3000~5000)

## 参考文献

[1] Pulli K, Baksheev A, Kornyakov K, et al. Realtime computer vision with OpenCV[J]. Queue, 2012, 10(4): 40.

[2] Cheng Shiwei,Sun Lingyun.A Survey on Visualization for Eye Tracking Data[J].Journal of Computer-Aided Design and Computer Graphics,2014,26(5):698-707.

[3]P. Xu, K. A. Ehinger, Y. Zhang, A. Finkelstein, S. R. Kulkarni, and J. Xiao. Turkergaze: crowdsourcing saliency with webcam based eye tracking[J].arXiv preprint arXiv:1504.06755, 2015.

